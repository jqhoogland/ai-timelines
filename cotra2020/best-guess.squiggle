// Based on Ajeya Cotra's 2020 "When compute required to train a transformative model may be attainable".
// - https://www.lesswrong.com/posts/KrJfoZzpSDpnrv9va/draft-report-on-ai-timelines
// 
// Adapted by: Jesse Hoogland

// Best guess 
// - https://docs.google.com/spreadsheets/d/1TjNQyVHvHlC-sZbcA7CRKcCp0NxV6MkkqBvL408xrJw/edit#gid=505210495

startYear = 2025
endYear = 2100

flopPer$(y) = {
    currFLOPPer$ = 4e17
    compute$HalvingTime = 2.5 // 1.5 to 3.5
    maxFLOPPer$ = 1e24 // 22 to 26

    t = y - startYear
    currFLOPPer$ * (exp((log(2) / compute$HalvingTime) * t)) / (1 + currFLOPPer$ / maxFLOPPer$ * exp(log(2)/compute$HalvingTime * t))  
}

frontierCountryGDP(y) = {
    // Our reference measurement comes from 2020, not 2025.
    t = y - 2020
    frontierCountryGDP2020 = 2.13e13
    growthRate = .03 // per year  // .02 to .05
    frontierCountryGDP2020 * (1 + growthRate)^(t)
}

spend(y) = {
    currSpend = 1e9 // in 2020 USD  1e8 to 1e10
    spendDoublingTime = 2.5  // 1 to 3
    currFracGWP = currSpend / frontierCountryGDP(startYear)
    maxFracGWP = .01 // of frontier GDP in 2020 USD  // .005 to .02

    t = y - startYear
    currSpend * (exp(log(2)/ spendDoublingTime * t)) / (1 + currFracGWP / maxFracGWP * exp(log(2) / spendDoublingTime * t))
}

flop(y) = {
    flopPer$(y) * spend(y)
}

log10Flop(y) = log10(flop(y))

// NOTE: All of the following are very coarse-grained approximations of Cotra's original estimates:
// https://docs.google.com/spreadsheets/d/1TjNQyVHvHlC-sZbcA7CRKcCp0NxV6MkkqBvL408xrJw/edit#gid=0

// Evolution anchor
//  "From earliest animals with neurons to modern humans"
//  ~1e41 FLOP
evolutionAnchorPDF = 34 to 47
evolutionAnchor(y) = cdf(evolutionAnchorPDF, log10Flop(y))

// Lifetime anchor 
//  "By a child's brain over the course of growing to be an adult"
//  ~1e24 FLOP
lifetimeAnchorPDF = 25 to 35 // 90% confidence
lifetimeAnchor(y) = cdf(lifetimeAnchorPDF, log10Flop(y))

// Neural network anchor
// "have about as many parameters as we would expect if we simply scaled up 
// the architectures of the largest current neural networks to run on 
// [as many] FLOP / subj sec. [as the human brain (~1e15 FLOP/s)].
nnShortAnchorPDF = 26 to 41
nnMediumAnchorPDF = 28 to 44
nnLongAnchorPDF = 30 to 46

nnShortAnchor(y) = cdf(nnShortAnchorPDF, log10Flop(y))
nnMediumAnchor(y) = cdf(nnMediumAnchorPDF, log10Flop(y))
nnLongAnchor(y) = cdf(nnLongAnchorPDF, log10Flop(y))

// Genome Anchor 
//  "have about as many parameters as there are bytes in the human genome (~7.5e8 bytes)"
genomeAnchorPDF = 28 to 40
genomeAnchor(y) = cdf(genomeAnchorPDF, log10Flop(y))


mixedPDF = mixture(
    evolutionAnchorPDF,
    lifetimeAnchorPDF,
    nnShortAnchorPDF,
    nnMediumAnchorPDF,
    nnLongAnchorPDF,
    genomeAnchorPDF,
    [
        .1,
        .05,
        .2,
        .3,
        .15,
        .1
    ]    
)

mixed(y) = cdf(mixedPDF, log10Flop(y))