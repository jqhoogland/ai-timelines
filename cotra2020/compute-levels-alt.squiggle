// See ./compute-levels.squiggle
// This directory replaces all instances of skew-normals with log-normals

// -- Reference ML models -----------------------------------------------------
// in flop/subj. s

tdGammonFlops = log10(4 * 2 * (198 * 40 + 40 * 4)) # IBM's 1992 backgammon model with 198 input neurons, 40 hidden neurons, and 4 output neurons. Assuming 4 moves/sec, 2 flop/param/move.
t5Flops = log10(11e9 * 2 * 4) # Google's T5 language model has ~11B parameters; I am assuming 2 flop / param / token and 4 tokens / subj sec
alphaStarFlops = log10(55e6 * 2 * 4.4) # 55 million weights are used in inference; I am guessing 2 flop / weight / timestep and ~4.4 timesteps / second
gpt3Flops = log10(175e9 * 2 * 4) # 175 billion parameters; I am assuming 2 flop / param / token and 4 tokens / subj sec

// -- Reference brains --------------------------------------------------------
// in Log10(flop/s or subj. s)

humanBrainFlopsLandauerLimit = log10(7e21)

humanBrainFlops = 10 to 20
mouseBrainFlops = 7 to 17
beeBrainFlops = 4 to 14
elegansFlops = 1 to 9

// -- Transformative model flop/subj. s vs. brain flop/s ----------------------
// How many more/less flop/subj. s do we need to train a transformative model?
// (Given 2020 algorithms & architectures)

// in OOMs 
modelFlopsVsBrainFlops = -4 to 5 // Note: Cotra specifies a median & scale, Squiggle prefers confidence intervals.
taiFlops = humanBrainFlops + modelFlopsVsBrainFlops


// -- Transformative model parameters -----------------------------------------

// How many forward passes per second? (in log units)
taiParams = {
    taiForwardPassPerSec = -1 to 1
    taiFlopPerParamPerForwardPass = 0 to 2
    taiFlopPerParamPerSec = taiFlopPerParamPerForwardPass + taiForwardPassPerSec // NOTE: Cotra uses a point estimate of 1.5 log10(flop/param/s) 
    taiFlops - taiFlopPerParamPerSec
}

// -- Sample complexity scaling laws ------------------------------------------

median(x) = quantile(x, 0.5)


// See Kaplan et al. 2020 & Hestness et al. 2017
scalingExponent = {
    kaplan2020ComputeOptimal = 0.37
    kaplan2020TargetAccuracy = 0.74
    linearERMSGDBounds = 1
    rlDatasetMainline = 0.78
    rlDatasetHigh = 1.22
    hestnessLow = 1.28
    hestnessHigh = 1.75

    0.4 to 1.2
}


// D = KP ^ a, where D = # of data points, K is some constant, P = # of parameters, and a is the scaling exponetn.
// Here, p should be constant, but a can be a distribution
getConstantFactor(params) = {
    params.d - params.a * params.p
}

// Reference point on curve
// NOTE: It's not clear to me where the 12 here actually comes from
constantFactor = getConstantFactor({p: 12, d: normal({mean: 11.2, stdev: 1.5}), a: scalingExponent})

taiSamples = {
    taiParamsMedian = median(taiParams)

    constantFactor + scalingExponent * taiParamsMedian 
}

// -- Training FLOP Landscape -------------------------------------------------

// Past and current effective flop per dollar
fourtiesFlopPerDollar = log10(500 * 5 * 365 * 24 * 60 * 60 / 6.3e9) # ENIAC computer flop per dollar (cost of $6.3B inflation-adjusted, 500 flop/s). I'm assuming a longer amortization period (five years)
sixtiesFlopPerDollar = 6.2 # 1964 flop per dollar, eyeballing from the charts in the previous notebook
currFlopPerDollar = log10(1.2e17) # 2020 flop per dollar, estimated from the V100 chip (see calculation in the document)

// Levels of spending
alphaStarSpend = log10(1.1e6) # Estimate of the cost of the AlphaStar training run
manhattanSpend = log10(30e9) # Manhattan Project cost $30B inflation-adjusted over five years 
apolloPeakSpend = log10(157e9) # Most expensive four years of the Apollo Project cost $157B inflation-adjusted 

// Hypothetical amounts of compute purchasable in the past or present
oldAlphaStarFlop = alphaStarSpend + fourtiesFlopPerDollar # Amount of flop that could be purchased by spending AlphaStar compute budget in 1945
manhattanFlop = manhattanSpend + fourtiesFlopPerDollar # Amount of flop that could be purchased by spending Manhattan Project money entirely on 1945 computers
apolloFlop = apolloPeakSpend + sixtiesFlopPerDollar # Amount of flop that could be purchased by spending Apollo Project money entirely on 1964 computers
alphaStarFlop = alphaStarSpend + currFlopPerDollar # Total flop in AlphaStar training run
modernMegaprojectFlop = manhattanSpend + currFlopPerDollar # Amount of flop that could be purchased by spending $30B today

// -- NN anchors --------------------------------------------------------------

modelSizeAnchor(params) = {
    flops = params.flops

    // Scaling law
    p = params.p
    a = params.a
    k = params.k

    horizonLen = params.horizonLen
    trainFlop = (flops + horizonLen) + (k + p * a)

    trainFlop
}

// Short-horizon: How many log(subj. s) of compute should we be able to simulate
nnShort = {
    modelSizeAnchor({
        flops: taiFlops,
        p: 14.3,
        a: scalingExponent,
        k: constantFactor,
        horizonLen: uniform(0, 3)
    })
}

nnMedium = {
    modelSizeAnchor({
        flops: taiFlops,
        p: 14.3,
        a: scalingExponent,
        k: constantFactor,
        horizonLen: uniform(3, 6)
    })
}

nnLong = {
    modelSizeAnchor({
        flops: taiFlops,
        p: 14.3,
        a: scalingExponent,
        k: constantFactor,
        horizonLen: uniform(6, 9)
    })
}

// -- Genome anchor -----------------------------------------------------------

genome = {
    genomeBytesMedian = log10(750e6)

    modelSizeAnchor({
        flops: taiFlops,
        p: normal({mean: genomeBytesMedian, stdev: 2}),
        a: scalingExponent,
        k: constantFactor,
        horizonLen: uniform(7, 9)
    })
}

// -- Lifetime anchor ---------------------------------------------------------

humanBrainSynapsesMedian = 14.5

lifetime = {
    lifetimeSeconds = 9 // ~32 years
    humanLifetimeFlop = humanBrainFlops + lifetimeSeconds
   
    trainFlopVsLifetime = 0 to 12

    humanLifetimeFlop + trainFlopVsLifetime
}


// -- Evolution anchor --------------------------------------------------------

evolution = {
    secInYear = log10(365 * 24 * 60 * 60)
    ancestorsAveragePop = uniform(19, 23) # Tomasik estimates ~1e21 nematodes, which I am taking as representative of the average ancestor
    evolutionaryTimeInSec = uniform(8.15, 9.45) + secInYear # 1 billion years since early neurons
    ancestorsAverageBrainFlops = elegansFlops
    ancestorsFlop = ancestorsAverageBrainFlops + evolutionaryTimeInSec + ancestorsAveragePop # Assuming the average brain size over evolutionary history is the size of C Elegans (~10,000 flop/s)
    ancestorsFlopMedian = median(ancestorsFlop)
    
    trainFlopVsEvolution = (0 to 10) - 10

    ancestorsFlop + trainFlopVsEvolution
}

// -- Update against levels of FLOP we can already afford ----------------------

partialTruncate(dist) = {
    noChanceThreshold = 6 
    whoKnowsThreshold = 11

    // TODO: Between the thresholds, distributions are multiplied by a fn linearly interpolating between 0 and 1
    // truncateLeft(dist, noChanceThreshold)

    // This is a placeholder
    truncateLeft(dist, (whoKnowsThreshold + noChanceThreshold) / 2)
}

largerThanAllAnchorPdf = 72 to 78
nnShortAnchorPdf = partialTruncate(nnShort)
nnMediumAnchorPdf = partialTruncate(nnMedium)
nnLongAnchorPdf = partialTruncate(nnLong)
genomeAnchorPdf = partialTruncate(genome)
lifetimeAnchorPdf = partialTruncate(lifetime)
evolutionAnchorPdf = partialTruncate(evolution)

mixedPdf = mixture(
    largerThanAllAnchorPdf,
    lifetimeAnchorPdf,
    nnShortAnchorPdf,
    genomeAnchorPdf,
    nnMediumAnchorPdf,
    nnLongAnchorPdf,
    evolutionAnchorPdf, 
    [.1, .05, .2, .1, .3, .15, .1]
)